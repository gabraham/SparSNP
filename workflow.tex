
\documentclass[a4paper,11pt]{article}

\usepackage{a4wide}
\usepackage[round]{natbib}
\usepackage{graphicx}
\usepackage{hyperref}

\title{SparSNP --- Workflow example}
\author{Gad Abraham gad.abraham@unimelb.edu.au}


\begin{document}

\maketitle

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{process.pdf}
\caption{Analysis workflow}
\label{fig:process}
\end{figure}


Here we describe a typical analysis using SparSNP.  We assume that we have two
datasets in PLINK~\citep{purcell2007} BED/BIM/FAM format, named
\texttt{discovery} and \texttt{validation}, on the same SNP microarray platform.
The phenotype in the FAM file can be discrete (1 for controls and 2 for cases)
or continuous.  In the following, we assume the user is working with a Unix-like
command line shell such as Bash.

\begin{enumerate}

   \item \textbf{Installation}\\

   Requirements:\\
   
      \begin{itemize}
	 \item Linux / Unix / Mac operating system, preferably 64-bit.
	 \item \textsf{R}, with packages ggplot2 ($\ge 0.9.3$), scales, grid, abind, ROCR
	 \item C compiler, gcc or clang
	 \item make
      \end{itemize}

   Download and install:
\begin{verbatim}
git clone git://github.com/gabraham/SparSNP
cd SparSNP
make
\end{verbatim}

   Prior to running SparSNP you must include the directory you unpacked it in, in the path:
\begin{verbatim}
export PATH=<PATH_TO_SPARSNP>:$PATH
\end{verbatim}

   \item \textbf{Quick Start}\\

   Assuming the data is called \texttt{my-data.bed}, \texttt{my-data.bim},
   \texttt{my-data.fam} (case sensitive) and it's case/control data:

      \begin{itemize}
	 \item \texttt{export PATH=<PATH\_TO\_SPARSNP>:\$PATH}
	 \item \texttt{crossval.sh my-data sqrhinge 2>\&1 | tee log}
	 \item \texttt{eval.R} to plot cross-validation AUC results in
	 \texttt{discovery/discovery\_AUC.pdf}
      \end{itemize}
   

   \item \textbf{Quality Control}\\
      SparSNP implements simple imputation of genotypes such that missing
      genotypes are randomly assigned the value \{0,1,2\} with probability
      proportional to the genotypes in non-missing samples of each
      SNP\footnote{Earlier versions assigned equal probability to each
      genotype.}, which
      does not introduce substantial bias to the model when the proportion of
      missingness is small and the genotypes are missing at random. We recommend
      removing samples and SNPs with high missingness, and testing for
      differential missingness between cases and controls.

      \begin{itemize}

      \item Remove markers with missingness $\ge 0.01$, MAF $\le 0.01$, and
      Hardy-Weinberg test for equilibrium in
      controls of $p\le 10^{-4}$, and samples with missingness $\ge 0.01$: \\
      \texttt{\$ plink --noweb --bfile my-data --geno 0.01 --mind 0.01
      \textbackslash \\ --maf 0.01 --hwe
      0.0001 \textbackslash \\
      --make-bed --out my-data-filtered
      }

      \item Test for differential missingness: \\
      \texttt{\$ plink --noweb --bfile my-data-filtered --missing} \\
      (remove SNPs as indicated by output)

      \item Test for sample relatedness with a threshold of $\hat{\pi}=0.05$: \\
      \texttt{\$ plink --noweb --bfile my-data-filtered --Z-genome --min 0.05} \\
      (remove related samples as indicated by output)

      \item Check for stratification using PCA, for example, using
      \texttt{smartpca} in Eigensoft~\citep{price2006}.

      \item Two locus test for detecting batch effects~\citep{lee2010b}. \\
      (remove SNPs as indicated by output)

      \end{itemize}

   \item \textbf{SparSNP on discovery data}


      \begin{itemize}

	 \item Note: your PLINK bed/bim/fam files must have a lower-case suffix
	 (i.e., bed not BED).

	 \item Run cross-validation. By default, $10\times10$-fold
	 cross-validation will be performed, allowing up to $\min \{N, p\}$ SNPs
	 in the model, using a case/control phenotype: \\ for classification
	 (case/control)\\ \texttt{\$ crossval.sh my-data-filtered sqrhinge}\\
	 and for continuous outputs (linear regression)\\ \texttt{\$ crossval.sh
	 my-data-filtered linear}\\ The \texttt{crossval.sh} script can be
	 modified to perform more cross-validation folds or to tune the model
	 parameters.

	 You can run SparSNP on 10 cores at once using\\
	 \texttt{\$ NUMPROCS=10 crossval.sh my-data-filtered sqrhinge}

	 You can run change the default output directory \texttt{discovery} to
	 \texttt{my-discovery} using\\
	 \texttt{\$ DIR=my-discovery-dir crossval.sh my-data-filtered sqrhinge}

	 \item Plot AUC and explained phenotypic and genetic variance in the
	 cross-validation replications: \\
	 \texttt{\$ eval.R} \\
	 Optionally, supply population prevalence $K=1\%$ and heritability $h^2_L=50\%$:\\
	 \texttt{\$ eval.R prev=0.01 h2l=0.5} \\
	 The plots \texttt{discovery\_AUC.pdf},
	 \texttt{discovery\_VarExp.pdf}, and \texttt{discovery\_GenVarExp.pdf}
	 will be produced in the directory \texttt{discovery} (the last two
	 plots will be produced only if you supply prevalence and/or
	 heritability).  The raw AUC and
	 explained variance data is stored in the \texttt{.Rdata} file named
	 \texttt{discovery.RData}.  
	 If used a non-standard directory, you need to specify it: \\
	 \texttt{\$ eval.R dir=my-discovery-dir prev=0.01 h2l=0.5} \\
	 Note that currently for \texttt{linear} models \texttt{eval.R} only
	 computes $R^2$ and not the explained heritability etc.

	 \item The set of models with best predictive ability will
	 automatically be chosen from the results, based on smoothing
	 of the AUC\footnote{The $\lambda$ grid must be fine enough
	 to produce good smooths. The default \texttt{NLAMBDA1=30} is usually
	 sufficient but may need to be increased in some cases.}.
	 The SNPs appearing in these models will be
	 tabulated according to how many time they were included over all
	 cross-validation folds. To inspect the SNPs selected by models that
	 maximise the predictive ability:\\
	 \texttt{head discovery/topsnps.txt}
	 \begin{verbatim}
RS Counts Proportion Replications
rs2050189 60 1 60
rs2187668 60 1 60
rs9357152 60 1 60
rs7774954 60 1 60
rs3129763 58 0.966666666666667 60
...
	 \end{verbatim}
	 The SNPs are ordered by the number of times they were included in a
	 model with non-zero weight (Counts) out of the total number of
	 cross-validation folds (Replications, i.e.
	 \texttt{NREPS}$\times$\texttt{NFOLDS}), also shown as a Proportion.
	 SNPs at the top of the list are more stably selected by the lasso and
	 are potentially more robust markers than SNPs at the bottom of the
	 list.

      \end{itemize}

   \item \textbf{Optional: Apply models to validation data}

      SparSNP models trained on the discovery dataset can be tested on an
      independent dataset, if one is available. Datasets can differ in terms of
      which SNPs are assayed, their ordering in the PLINK files, and their minor
      allele frequencies\footnote{Strand flips will cause some predictor SNPs to
      be ignored, see
      \url{http://pngu.mgh.harvard.edu/~purcell/plink/dataman.shtml\#flip} to
      fix this prior to running the prediction stage.}. SparSNP is completely
      oblivious to these differences and cannot detect them, hence we use PLINK
      scoring. The one caveat is that PLINK scoring does not have an intercept
      term, which we must add on. The process is:
      \begin{itemize}

	 \item Extract a consensus model from the training data using
	 \texttt{getmodels.R}, requesting a certain number of SNPs in the
	 model:

	 \texttt{\$ getmodels.R nzreq=256}

	 And if you used a non-standard discovery directory:\\
	 \texttt{\$ getmodels.R nzreq=256 dir=my-discovery-dir}

	 \item Call \texttt{predict.sh} on the validation dataset
	 \texttt{my-validation-data} which will
	 call PLINK scoring internally:

	 \texttt{\$ predict.sh my-validation-data}

	 If you used a non-standard discovery directory:\\
	 \texttt{\$ DIR=my-discovery-dir predict.sh my-validation-data}

	 Optionally, you can declare OUTDIR to specify a directory other than
	 \texttt{predict} (say \texttt{my-validation-dir}), and use multi-processing if
	 you have multiple cores:

	 \texttt{\$ NUMPROCS=10 OUTDIR=my-validation-dir \textbackslash \\
	    predict.sh my-validation-data}

	 \item Call \texttt{evalprofile.R} to compute ROC/AUC on the
	 validation data, optionally with the prevalence to
	 allow plotting PPV/NPV:

	 \texttt{\$ evalprofile.R model=sqrhinge prev=0.01}

	 If you used an non-default directory for discovery (say
	 \texttt{my-discovery-dir}) and/or non-default
	 for validation (say \texttt{my-validation-dir}), then specify it:

	 \texttt{\$ evalprofile.R model=sqrhinge prev=0.01 \textbackslash \\
	 indir=my-discovery-dir outdir=my-validation-dir}

	 The results will be saved in the directory you specified, in the file
	 \texttt{results.RData}.

	 You can now load the results (assuming you used the default output
	 directory \texttt{predict}), stored as a list, one element per model
	 in the path, plot the results or compute new one curves using the
	 ROCR \texttt{pred} object:

\begin{verbatim}
> load("predict/results.RData")
> length(res)
[1] 30
> names(res[[10]])
[1] "pred"    "perf"    "sens"    "spec"    "cutoffs" "ppv"     "npv"   
> library(ROCR)
> plot(res[[10]]$perf) # ROC curve for 10th model
> plot(performance(res[[10]]$pred, "prec", "rec")) # precision-recall
\end{verbatim}

      \item \texttt{evalprofile.R} can compute $R^2$ for linear
      regression models, in which case prevalence shouldn't be supplied:

	 \texttt{\$ evalprofile.R model=linear outdir=my-validation-dir}

	 and if you used a non-standard discovery directory:

	 \texttt{\$ evalprofile.R model=linear \textbackslash \\
	    indir=my-discovery-dir outdir=my-validation-dir}

	 Note that an alternative phenotype file is currently not supported
	 for \texttt{evalprofile.R}, that is, the validation FAM file must
	 contain a phenotype (not \texttt{-9}).

      \end{itemize}



   \item \textbf{Other post processing}

      \begin{itemize}
	 \item The model weights are stored in each cross-validation
	 directory\\
	 \texttt{discovery/crossvalXX/beta.csv.XX.XX}\\
	 using a sparse text format $<$index,weight$>$,
	 where index is the zero-based index of the SNP in the data (0 is the
	 intercept), and weight is the model weight (a real number).
	 The weights can be read into \textsf{R} 
	 (using \texttt{read.table} with \texttt{sep=",", header=FALSE}) or any other tool for
	 visualisation or for validating the model on other datasets.
      \end{itemize}
      
       \item \textbf{Optional parameters}



Some options that can be set by setting the environment variables before
calling \texttt{crossval.sh}:
\begin{itemize}

   \item \texttt{NUMPROCS}: number of processes to use in parallel, should be
   between 1 and the number of cross-validation replications \texttt{NREPS} (not folds),
   (default=1)

   \item \texttt{LAMBDA2}: $\ell_2$  penalty for elastic-net (default=0)

   \item \texttt{NFOLDS}: number of cross-validation folds (default=10)

   \item \texttt{NREPS}: number of cross-validation replications (default=10)

   \item \texttt{NZMAX}: maximum number of SNPs to allow in model
   (default=$\min \{N, p \}$)

   \item \texttt{NLAMBDA1}: number of $\lambda$ penalties on the grid
   (default=30)

   \item \texttt{L1MIN}: multiplier on smallest $\lambda$ used; it should
   be a some positive fraction such as 0.01. Setting it lower will increase
   the number of SNPs in the models, but will also increase computational time
   (default=0.001)

   \item \texttt{PHENO}: for an alternative phenotype file (equivalent to PLINK
   \texttt{--pheno}). The file must be in the format:\\
   FamilyID IndividualID PhenotypeA PhenotypeB ... \\
   \emph{without a header line}.
   When $K$ phenotypes are available SparSNP will fit a multivariate
   model equivalent to $K$ separate models.

\end{itemize}
Example of using the optional parameters:

\texttt{NUMPROCS=10 LAMBDA2=0.1 NFOLDS=3 NREPS=10 NZMAX=500  \textbackslash \\
crossval.sh my-data sqrhinge 2>\&1 | tee log}

\end{enumerate}

\bibliography{sparsnp_bmc}
\bibliographystyle{unsrtnat}

\end{document}

